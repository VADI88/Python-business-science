{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge #2 - Make a New Forecasting Function\n",
    "\n",
    "<small>Python for Data Science Automation Course (DS4B 101-P)</small><br>\n",
    "<small>Business Science</small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Summary\n",
    "\n",
    "This is a short challenge to extend your ability to review python `sktime` documentation. You will go through a series of questions related to:\n",
    "\n",
    "1. Creating a New Forecasting Function using Exponential Smoothing\n",
    "\n",
    "2. Forecasting Revenue By Customers\n",
    "\n",
    "### Data Science Request\n",
    "\n",
    "Your Data Science Manager has requested you to implement a second forecasting algorithm called \"Exponential Smoothing\" or ETS. Your goal is to leverage your knowledge of the existing ARIMA function you've created and make a new function that swaps ARIMA for ETS.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "1. Use your `sktime` documentation sloothing skills to make a a new ETS forecasting function.\n",
    "\n",
    "2. Apply the function to forecast revenue by customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in the data, make sure your current working directory is set to the project directory. Two useful [jupyter magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html) are:\n",
    "\n",
    "1. `%pwd`: [Print working directory](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-cd) (you can detect your current directory)\n",
    "2. `%cd`: You can [change directory](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-cd) to your working directory using relative paths or full paths. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:04:55.394935Z",
     "start_time": "2025-07-28T22:04:55.384524Z"
    }
   },
   "source": "%pwd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vadiveld/PycharmProjects/Python-Business-science/Challenge 1 2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:04:43.265997Z",
     "start_time": "2025-07-28T22:04:43.237780Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from path import Path\n",
    "\n",
    "from transformer.bike_order_transformer import BikeOrderTransformer\n",
    "from my_pandas_extension.timeseries_func import summarize_by_time\n",
    "\n",
    "database_folder_path = Path(\"../data/database\")\n",
    "\n",
    "conn_string = f\"sqlite:///{database_folder_path}/bikes_order_database.sqlite\"\n",
    "\n",
    "bike_order_line_df = BikeOrderTransformer(conn_string).transform_data()\n",
    "\n",
    "bike_order_line_df[\"order_date\"] = pd.to_datetime(bike_order_line_df[\"order_date\"])"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'my_pandas_extensions'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbike_order_transformer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BikeOrderTransformer\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmy_pandas_extensions\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtimeseries\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m summarize_by_time\n\u001B[1;32m      9\u001B[0m database_folder_path \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/database\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m conn_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msqlite:///\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdatabase_folder_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/bikes_order_database.sqlite\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'my_pandas_extensions'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:04:23.884383Z",
     "start_time": "2025-07-28T22:04:23.860441Z"
    }
   },
   "cell_type": "code",
   "source": "bike_order_line_df.head()",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bike_order_line_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mbike_order_line_df\u001B[49m\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'bike_order_line_df' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make use of our `arima_forecast()` function as a starting point for modification. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:02:46.208309Z",
     "start_time": "2025-07-28T22:02:42.577153Z"
    }
   },
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pydantic import (\n",
    "    validate_call,\n",
    "    StrictFloat,\n",
    "    ConfigDict,\n",
    "    Field,\n",
    "    StrictInt,\n",
    ")\n",
    "from typing import Literal, Annotated, Optional\n",
    "\n",
    "\n",
    "@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n",
    "def ets_forecast(\n",
    "        data: pd.DataFrame,\n",
    "        h: Annotated[int, Field(strict=True, gt=0)],\n",
    "        sp: Literal[3, 6, 12, 24],\n",
    "        seasonal: Optional[Literal['add', 'null']] = None,\n",
    "        trend: Optional[Literal['add', 'null']] = None,\n",
    "        alpha: Annotated[StrictFloat, Field(strict=True, gt=0, lt=1)] = 0.95,\n",
    "        suppress_warmings=True,\n",
    "        *args,\n",
    "        **kwargs):\n",
    "    # Checks\n",
    "\n",
    "    # Handle Inputs ----\n",
    "    df = data\n",
    "\n",
    "    # FOR LOOP ----\n",
    "\n",
    "    model_results_dict = {}\n",
    "    for col in tqdm(df.columns, mininterval=0):\n",
    "        # Series Extraction\n",
    "        y = df[col]\n",
    "\n",
    "        # Modeling\n",
    "        forecaster = AutoETS(\n",
    "                sp=sp,\n",
    "                seasonal=seasonal,\n",
    "                trend=trend,\n",
    "                *args,\n",
    "                **kwargs\n",
    "        )\n",
    "\n",
    "        forecaster.fit(y)\n",
    "\n",
    "        predictions = forecaster.predict(fh=np.arange(1, h + 1))\n",
    "        predictions_interval = forecaster.predict_interval(coverage=alpha)\n",
    "        predictions_interval.index = predictions.index\n",
    "\n",
    "        predictions_return_df = pd.concat([y, predictions, predictions_interval], axis=1)\n",
    "\n",
    "        predictions_return_df = pd.concat([y, predictions, predictions_interval], axis=1)\n",
    "\n",
    "        predictions_return_df.columns = [\"value\", \"prediction\", \"ci_lo\", \"ci_hi\"]\n",
    "\n",
    "        model_results_dict[col] = predictions_return_df\n",
    "\n",
    "    # Stack Each Dict Element on Top of Each Other\n",
    "    model_results_df = pd.concat(\n",
    "            model_results_dict,\n",
    "            axis=0\n",
    "    )\n",
    "\n",
    "    # Handle Names\n",
    "    nms = [*df.columns.names, *df.index.names]\n",
    "    model_results_df.index.names = nms\n",
    "\n",
    "    # Reset Index\n",
    "    ret = model_results_df.reset_index()\n",
    "\n",
    "    # Drop columns containing \"level\"\n",
    "    cols_to_keep = ~ret.columns.str.startswith(\"level_\")\n",
    "\n",
    "    ret = ret.iloc[:, cols_to_keep]\n",
    "\n",
    "    return ret"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Make an ETS Forecasting Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy the `arima_forecast`\n",
    "2. Import the [AutoETS Function](https://www.sktime.org/en/v0.5.3/api_reference/modules/auto_generated/sktime.forecasting.ets.AutoETS.html?highlight=autoets) from **version 0.5.3** of `sktime`\n",
    "3. Rename the `arima_forecast()` function to `ets_forecast()`\n",
    "4. Change the internals of the function to swap out `AutoARIMA()` for `AutoETS()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Test the `ets_forecast()` function"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bike_sales_cat2_m_df = bike_order_line_df.summarize_by_time(  # type: ignore\n",
    "        date_column=\"order_date\",\n",
    "        value_column=[\"total_price\"],\n",
    "        groups=[\"category_2\"],\n",
    "        rules=\"MS\",\n",
    "        time_format=\"period\",\n",
    ")\n",
    "\n",
    "bike_sales_cat2_m_df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Start with `bike_sales_cat2_m_df`\n",
    "2. Use the `ets_forecast()` function to forecast with the following parameters:\n",
    "```\n",
    "ets_forecast(\n",
    "    data     = bike_sales_cat2_m_df,\n",
    "    h        = 12, \n",
    "    sp       = 12, \n",
    "    seasonal = \"add\", # For additive seasonality \n",
    "    trend    = \"add\"  # For additive trend\n",
    ")\n",
    "```\n",
    "3. Troubleshoot the Prediction \"Not Yet Implemented Error\" \n",
    "    - Go back to your function and make changes to remove the confidence interval\n",
    "    - Remove the `alpha` argument from the function\n",
    "4. Use `.groupby()` to group by `category_2`.\n",
    "5. Use `.plot()` to plot with `x = 'order_date'."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Code\n",
    "\n",
    "fcast = ets_forecast(\n",
    "        data=bike_sales_cat2_m_df,\n",
    "        h=12,\n",
    "        sp=12,\n",
    "        seasonal=\"add\",  # For additive seasonality\n",
    "        trend=\"add\"  # For additive trend\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fcast.groupby('category_2').plot(x='order_date')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice Work\n",
    "\n",
    "This challenge tested your ability to research documentatoin and debug code. If you nailed it, you're doing awesome. If you didn't, guess what - You're still awesome too! Keep in mind you're learning, it takes time, and these challenges are meant to be *challenging*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
